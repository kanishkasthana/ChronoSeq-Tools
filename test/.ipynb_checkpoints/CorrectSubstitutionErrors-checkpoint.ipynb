{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author Kanishk Asthana kasthana@eng.ucsd.edu\n",
    "import pysam\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import shared_memory,Process,Manager\n",
    "from multiprocessing.managers import SharedMemoryManager\n",
    "#For writing output to the stdout in realtime\n",
    "def write(*something):\n",
    "    print(*something)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#Default Values\n",
    "bamFileName=\"/stg3/data1/kanishk2/Temp/Sample_test.bam\"\n",
    "outBamFileName=\"/stg3/data1/kanishk2/Temp/SubCorrected_test.bam\"\n",
    "MIN_UMI_COUNT=20 #Minimum UMI count for Barcode to be considered for Collapse. Not counting UMIs for simplicity.Change this later because it breaks easily. #ToDO\n",
    "SUBSTITUTION_ERROR_FREQ=0.85 #Minimum frequency of majority barcode in substitution pairs needed for collapse\n",
    "num_cores=10 #Change this later to match same number of cores as STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Processing BAM file at 2022-07-24 16:47:32.334130 . Getting Cell Barcodes to correct Illumina Sequencing Base Substitution Errors!\n",
      "Finished processing BAM file at  2022-07-24 16:47:35.113043 . Total time taken  0:00:02.778906\n",
      "3384 Cell barcodes have enough UMIs for further processing.\n",
      "CPU times: user 2.77 s, sys: 53.1 ms, total: 2.82 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "def parse_file(input_filename):\n",
    "    if not os.path.isfile(input_filename):\n",
    "        raise argparse.ArgumentTypeError(\"File does not exist. Please use a valid file path.\")\n",
    "    return(input_filename)\n",
    "    \n",
    "def check_umi(input_umi):\n",
    "    value=int(input_umi)\n",
    "    assert value>0,\"Please enter positive values only for UMI Count Filter!\"\n",
    "    return value\n",
    "\n",
    "parser=argparse.ArgumentParser(description=\"Script to detect and Correct Substitution errors in the Cell Barcodes. These errors are likely sequencing errors and not Bead Synthesis Errors\")\n",
    "parser.add_argument(\"INPUT_FILENAME\",help=\"Aligned Merged and Gene labeled BAM file for Correcting Substitution Errors.\", type=parse_file)\n",
    "parser.add_argument(\"OUTPUT_FILENAME\",help=\"Please enter a Valid Path for the Error Corrected output BAM file.\",type=str)\n",
    "parser.add_argument(\"-umi\",\"--MIN_UMI\", help=\"Minimum UMI count per barcode to be considered for Collapse. Default Value is 20.\",type=check_umi)\n",
    "args=parser.parse_args()\n",
    "write(args)\n",
    "\n",
    "if args.MIN_UMI is not None:\n",
    "    MIN_UMI_COUNT=args.MIN_UMI\n",
    "\n",
    "bamFileName=args.INPUT_FILENAME\n",
    "outBamFileName=args.OUTPUT_FILENAME\n",
    "'''\n",
    "script_start_time=datetime.now()\n",
    "\n",
    "class CellBarcode:\n",
    "    CellBarcodesWithEnoughCounts=[]\n",
    "    NumberofBarcodesCollapsed=0\n",
    "    def __init__(self,barcode,umi):\n",
    "        self.count=1 #Number of reads with that Barcode. When initializing you count the barcode you initialize with\n",
    "        self.barcode=barcode\n",
    "        self.barcodeToReturn=self #This will be updated with a different reference if this barcode is merged with another\n",
    "        self.umi_dict={}\n",
    "        self.umi_dict[umi]=1\n",
    "        \n",
    "    def increase_count(self,umi):\n",
    "        self.count+=1 #Increase count if you see a barcode\n",
    "        if umi in self.umi_dict:\n",
    "            self.umi_dict[umi]+=1\n",
    "        else:\n",
    "            self.umi_dict[umi]=1\n",
    "            \n",
    "    def computeHasEnoughCounts(self):\n",
    "        if len(self.umi_dict.keys())>MIN_UMI_COUNT:\n",
    "            CellBarcode.CellBarcodesWithEnoughCounts.append(self.barcode)\n",
    "            \n",
    "    def combineIfSubstitution(self,CellBarcode2):\n",
    "        largerBarcode=self.barcodeToReturn\n",
    "        smallerBarcode=CellBarcode2.barcodeToReturn\n",
    "        if smallerBarcode.count>largerBarcode.count:\n",
    "            largerBarcode=CellBarcode2.barcodeToReturn\n",
    "            smallerBarcode=self.barcodeToReturn\n",
    "        freq=largerBarcode.count/(largerBarcode.count+smallerBarcode.count)\n",
    "        if freq>SUBSTITUTION_ERROR_FREQ:\n",
    "            smallerBarcode.barcodeToReturn=largerBarcode\n",
    "            largerBarcode.count+=smallerBarcode.count\n",
    "            CellBarcode.NumberofBarcodesCollapsed+=1\n",
    "\n",
    "barcode_dict={}\n",
    "\n",
    "#If you get an error here your file probably not correctly formated. Make sure you have a header.\n",
    "bamFile=pysam.AlignmentFile(bamFileName,\"rb\")\n",
    "BamRecords=bamFile.fetch(until_eof=True)\n",
    "\n",
    "start_time=datetime.now()\n",
    "prevMil=start_time\n",
    "write(\"Started Processing BAM file at\",start_time,\". Getting Cell Barcodes to correct Illumina Sequencing Base Substitution Errors!\")\n",
    "\n",
    "total_records=0\n",
    "for record in BamRecords:\n",
    "    \n",
    "\n",
    "    #For printing progress\n",
    "    total_records+=1\n",
    "    if total_records%1000000==0:\n",
    "        time_taken=datetime.now()-prevMil\n",
    "        write(\"Finished processing \",total_records,\"\\trecords at\",datetime.now(),\". Previous 1000000 Records took \",time_taken.total_seconds(),\"s\")\n",
    "        prevMil=datetime.now()\n",
    "    \n",
    "\n",
    "    #Main Logic\n",
    "    cell_barcode=record.get_tag('XC')\n",
    "    umi=record.get_tag('XM')\n",
    "    \n",
    "    if cell_barcode in barcode_dict:\n",
    "        barcode_dict[cell_barcode].increase_count(umi)\n",
    "    else:\n",
    "        barcode_dict[cell_barcode]=CellBarcode(cell_barcode,umi)\n",
    "\n",
    "\n",
    "total_time=datetime.now()-start_time\n",
    "write(\"Finished processing BAM file at \",datetime.now(),\". Total time taken \",total_time)\n",
    "\n",
    "bamFile.close()\n",
    "\n",
    "for barcode in barcode_dict.keys():\n",
    "    barcode_dict[barcode].computeHasEnoughCounts()\n",
    "\n",
    "write(len(CellBarcode.CellBarcodesWithEnoughCounts),\"Cell barcodes have enough UMIs for further processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency 0.85\n",
      "145 barcodes pairs were collapsed!\n",
      "CPU times: user 7.51 s, sys: 17.8 ms, total: 7.53 s\n",
      "Wall time: 7.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def hammingDistance(barcode1,barcode2):\n",
    "    distance=0\n",
    "    for i in range(0,len(barcode1)):\n",
    "        if barcode1[i]!=barcode2[i]:\n",
    "            distance+=1\n",
    "    return distance\n",
    "\n",
    "write(\"Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency\",SUBSTITUTION_ERROR_FREQ)\n",
    "indices=np.triu_indices(len(CellBarcode.CellBarcodesWithEnoughCounts),1)#Use diagnal offset=1. We don't want distance of barcodes with themself\n",
    "for i in range(0,len(indices[0])):\n",
    "    firstBarcode=CellBarcode.CellBarcodesWithEnoughCounts[indices[0][i]]\n",
    "    secondBarcode=CellBarcode.CellBarcodesWithEnoughCounts[indices[1][i]]\n",
    "    if hammingDistance(firstBarcode,secondBarcode)==1:\n",
    "        barcode_dict[firstBarcode].combineIfSubstitution(barcode_dict[secondBarcode])\n",
    "\n",
    "write(CellBarcode.NumberofBarcodesCollapsed,\"barcodes pairs were collapsed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.triu_indices(len(CellBarcode.CellBarcodesWithEnoughCounts),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1=[]\n",
    "for i in range(0,len(indices[0])):\n",
    "    lst1.append((indices[0][i],indices[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length=len(CellBarcode.CellBarcodesWithEnoughCounts)\n",
    "lst2=[]\n",
    "for i in range(0,vector_length-1):\n",
    "    for j in range(i+1,vector_length):\n",
    "        lst2.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5724036"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5724036"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1==lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency 0.85\n",
      "145 barcodes pairs were collapsed!\n",
      "CPU times: user 6.43 s, sys: 2.87 ms, total: 6.43 s\n",
      "Wall time: 6.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def hammingDistance(barcode1,barcode2):\n",
    "    distance=0\n",
    "    for i in range(0,len(barcode1)):\n",
    "        if barcode1[i]!=barcode2[i]:\n",
    "            distance+=1\n",
    "    return distance\n",
    "\n",
    "vector_length=len(CellBarcode.CellBarcodesWithEnoughCounts)\n",
    "write(\"Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency\",SUBSTITUTION_ERROR_FREQ)\n",
    "#Calculating Distances for the upper triangle of the distance matrix.\n",
    "for i in range(0,vector_length-1):\n",
    "    for j in range(i+1,vector_length):\n",
    "        firstBarcode=CellBarcode.CellBarcodesWithEnoughCounts[i]\n",
    "        secondBarcode=CellBarcode.CellBarcodesWithEnoughCounts[j]\n",
    "        if hammingDistance(firstBarcode,secondBarcode)==1:\n",
    "            barcode_dict[firstBarcode].combineIfSubstitution(barcode_dict[secondBarcode])\n",
    "\n",
    "write(CellBarcode.NumberofBarcodesCollapsed,\"barcodes pairs were collapsed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency 0.85\n",
      "Spliting Compressed Hamming Distance Matrix computation over multiple CPUs by dividing into chunks:\n",
      "[(0, 572403), (572404, 1144806), (1144807, 1717209), (1717210, 2289612), (2289613, 2862015), (2862016, 3434418), (3434419, 4006821), (4006822, 4579224), (4579225, 5151627), (5151628, 5724035)]\n",
      "0 572403\n",
      "3384\n",
      "(2, 5724036)\n",
      "572404 1144806\n",
      "3384\n",
      "(2, 5724036)\n",
      "1144807 1717209\n",
      "3384\n",
      "(2, 5724036)\n",
      "1717210 2289612\n",
      "3384\n",
      "(2, 5724036)\n",
      "2289613 2862015\n",
      "3384\n",
      "(2, 5724036)\n",
      "2862016 3434418\n",
      "3384\n",
      "(2, 5724036)\n",
      "3434419 4006821\n",
      "3384\n",
      "(2, 5724036)\n",
      "4006822 4579224\n",
      "3384\n",
      "(2, 5724036)\n",
      "4579225 5151627\n",
      "3384\n",
      "(2, 5724036)\n",
      "5151628 5724035\n",
      "3384\n",
      "(2, 5724036)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-87:\n",
      "Traceback (most recent call last):\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "KeyboardInterrupt\n",
      "Process Process-91:\n",
      "Traceback (most recent call last):\n",
      "Process Process-93:\n",
      "Process Process-89:\n",
      "Process Process-97:\n",
      "Process Process-95:\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-101:\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-105:\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 414, in __getitem__\n",
      "    self._get_packing_format(position),\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 363, in _get_packing_format\n",
      "    self._offset_packing_formats + position * 8\n",
      "Process Process-99:\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<timed exec>\", line 32, in ParallelHamming\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 412, in __getitem__\n",
      "    + sum(self._allocated_bytes[:position])\n",
      "Process Process-103:\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<timed exec>\", line 32, in ParallelHamming\n",
      "Traceback (most recent call last):\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "  File \"<timed exec>\", line 32, in ParallelHamming\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "  File \"<timed exec>\", line 37, in ParallelHamming\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2, in append\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/managers.py\", line 834, in _callmethod\n",
      "    conn.send((self._id, methodname, args, kwds))\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 412, in __getitem__\n",
      "    + sum(self._allocated_bytes[:position])\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "  File \"<timed exec>\", line 31, in ParallelHamming\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 421, in __getitem__\n",
      "    back_transform = self._get_back_transform(position)\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 380, in _get_back_transform\n",
      "    self._offset_back_transform_codes + position\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 497, in _offset_back_transform_codes\n",
      "    return self._offset_packing_formats + self._list_len * 8\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 493, in _offset_packing_formats\n",
      "    return self._offset_data_start + sum(self._allocated_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/shared_memory.py\", line 489, in _offset_data_start\n",
      "    return (self._list_len + 1) * 8  # 8 bytes per \"q\"\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stg1/data2/kanishk/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write(\"Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency\",SUBSTITUTION_ERROR_FREQ)\n",
    "indices=np.triu_indices(len(CellBarcode.CellBarcodesWithEnoughCounts),1)#Use diagnal offset=1. We don't want distance of barcodes with themself\n",
    "indices=np.array(indices)\n",
    "shm = shared_memory.SharedMemory(create=True, size=indices.nbytes)\n",
    "indices_shared=np.ndarray(indices.shape, dtype=indices.dtype, buffer=shm.buf)\n",
    "indices_shared[:]=indices[:]\n",
    "\n",
    "smm = SharedMemoryManager()\n",
    "smm.start()\n",
    "CellBarcodesWithEnoughCounts_shared=smm.ShareableList(CellBarcode.CellBarcodesWithEnoughCounts)\n",
    "\n",
    "#Generating Indices for Iterating over for Calculating Hamming Distance. This will help split the matrix into equal chunks to compute on.\n",
    "chunk_size=int(len(indices[0])/num_cores)\n",
    "chunk_lst=[]\n",
    "for i in range(0,num_cores-1):\n",
    "    if i!=0:\n",
    "        chunk_lst.append((i*chunk_size+1,(i+1)*chunk_size))\n",
    "    else:\n",
    "        chunk_lst.append((0,chunk_size))\n",
    "chunk_lst.append((chunk_size*(num_cores-1)+1,len(indices[0])-1))\n",
    "print(\"Spliting Compressed Hamming Distance Matrix computation over multiple CPUs by dividing into chunks:\")\n",
    "print(chunk_lst)\n",
    "\n",
    "def ParallelHamming(chunk_tuple,Barcodes,indices,results):\n",
    "    start,end=chunk_tuple\n",
    "    print(start,end)\n",
    "    print(len(Barcodes))\n",
    "    print(indices.shape)\n",
    "    for i in range(start,end+1):\n",
    "        distance=0\n",
    "        firstBarcode=Barcodes[indices[0][i]]\n",
    "        secondBarcode=Barcodes[indices[1][i]]\n",
    "        for j in range(0,len(firstBarcode)):\n",
    "            if firstBarcode[j]!=secondBarcode[j]:\n",
    "                distance+=1\n",
    "        if distance==1:\n",
    "            results.append((indices[0][i],indices[1],[i]))\n",
    "\n",
    "#Start Separate Processes on Chunks            \n",
    "result_indices_from_cpus=[]\n",
    "process_for_cpus=[]\n",
    "for i in range(0,num_cores):\n",
    "    results_for_cpu=Manager().list()\n",
    "    result_indices_from_cpus.append(results_for_cpu)\n",
    "    pr=Process(target=ParallelHamming,args=(chunk_lst[i],CellBarcodesWithEnoughCounts_shared,indices_shared,results_for_cpu))\n",
    "    process_for_cpus.append(pr)\n",
    "    pr.start()\n",
    "    \n",
    "for i in range(0,num_cores):\n",
    "    process_for_cpus[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea9449c2daca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Iterate on Indices Tuples to combine barcodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindices_tuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfirstIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecondIndex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfirstBarcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCellBarcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCellBarcodesWithEnoughCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirstIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msecondBarcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCellBarcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCellBarcodesWithEnoughCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msecondIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#Combine the Chunks into a single list that will be iterated on to combined the barcodes\n",
    "final_result=[]\n",
    "for result in result_indices_from_cpus:\n",
    "    for index_tuple in result:\n",
    "        final_result.append(index_tuple)\n",
    "\n",
    "#Iterate on Indices Tuples to combine barcodes.\n",
    "for indices_tuple in final_result:\n",
    "    firstIndex,secondIndex=indices_tuple\n",
    "    firstBarcode=CellBarcode.CellBarcodesWithEnoughCounts[firstIndex]\n",
    "    secondBarcode=CellBarcode.CellBarcodesWithEnoughCounts[secondIndex]\n",
    "    barcode_dict[firstBarcode].combineIfSubstitution(barcode_dict[secondBarcode])\n",
    "\n",
    "write(CellBarcode.NumberofBarcodesCollapsed,\"barcodes pairs were collapsed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smm.shutdown()\n",
    "shm.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Pairwise Hamming Distances between Barcodes! This may take some time. O(n^2) operation\n",
      "Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency 0.85\n",
      "145 barcodes pairs were collapsed!\n",
      "CPU times: user 28.6 s, sys: 16.9 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def hammingDistance(barcode1,barcode2):\n",
    "    distance=np.uint8(0)\n",
    "    barcode1=barcode1[0]\n",
    "    barcode2=barcode2[0]\n",
    "    for i in range(0,len(barcode1)):\n",
    "        if barcode1[i]!=barcode2[i]:\n",
    "            distance+=np.uint8(1)\n",
    "    return distance\n",
    "\n",
    "write(\"Calculating Pairwise Hamming Distances between Barcodes! This may take some time. O(n^2) operation\")\n",
    "barcodes_array=np.array(CellBarcode.CellBarcodesWithEnoughCounts)\n",
    "barcodes_array=barcodes_array.reshape(-1,1)\n",
    "compressed_distances=pdist(barcodes_array,hammingDistance)\n",
    "\n",
    "write(\"Collapsing Barcodes at a Hamming Distance of 1 and with the Major Barcode present above frequency\",SUBSTITUTION_ERROR_FREQ)\n",
    "#Getting Truth vector for all Barcode pairs with Hamming Distance of 1\n",
    "truth_vector=compressed_distances==1\n",
    "#Getting Indices for Barcodes pairs in the Truth Vector\n",
    "indices=np.triu_indices(len(CellBarcode.CellBarcodesWithEnoughCounts),1)#Use diagnal offset=1. We don't want distance of barcodes with themself\n",
    "for i in range(0,len(truth_vector)):\n",
    "    if truth_vector[i]:\n",
    "        firstBarcode=CellBarcode.CellBarcodesWithEnoughCounts[indices[0][i]]\n",
    "        secondBarcode=CellBarcode.CellBarcodesWithEnoughCounts[indices[1][i]]\n",
    "        barcode_dict[firstBarcode].combineIfSubstitution(barcode_dict[secondBarcode])\n",
    "\n",
    "write(CellBarcode.NumberofBarcodesCollapsed,\"barcodes pairs were collapsed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Writing Updated BAM file at 2022-07-23 20:03:41.490016 .\n",
      "Finished processing BAM file at  2022-07-23 20:03:52.275324 . Total time taken  0:00:10.785258\n",
      "Total Execution Time: 0:01:25.270978\n"
     ]
    }
   ],
   "source": [
    "#Writing to new File with Updated Barcodes\n",
    "bamFile=pysam.AlignmentFile(bamFileName,\"rb\")\n",
    "BamRecords=bamFile.fetch(until_eof=True)\n",
    "outBamFile=pysam.AlignmentFile(outBamFileName,\"wb\",template=bamFile)\n",
    "\n",
    "start_time=datetime.now()\n",
    "prevMil=start_time\n",
    "write(\"Started Writing Updated BAM file at\",start_time,\".\")\n",
    "\n",
    "total_records=0\n",
    "for record in BamRecords:    \n",
    "\n",
    "    #For printing progress\n",
    "    total_records+=1\n",
    "    if total_records%1000000==0:\n",
    "        time_taken=datetime.now()-prevMil\n",
    "        write(\"Finished processing \",total_records,\"\\trecords at\",datetime.now(),\". Previous 1000000 Records took \",time_taken.total_seconds(),\"s\")\n",
    "        prevMil=datetime.now()\n",
    "    \n",
    "    #Main Logic\n",
    "    cell_barcode=record.get_tag('XC')\n",
    "    updated_barcode=barcode_dict[cell_barcode].barcodeToReturn.barcode #Getting Updated Barcode\n",
    "    record.set_tag('XC',updated_barcode)\n",
    "    outBamFile.write(record)\n",
    "\n",
    "total_time=datetime.now()-start_time\n",
    "write(\"Finished processing BAM file at \",datetime.now(),\". Total time taken \",total_time)\n",
    "\n",
    "bamFile.close()\n",
    "outBamFile.close()\n",
    "\n",
    "write(\"Total Execution Time:\",datetime.now()-script_start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
